{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ast import literal_eval\n",
    "from configparser import ConfigParser\n",
    "from io import BytesIO\n",
    "\n",
    "import click\n",
    "import comet_ml\n",
    "import torch\n",
    "from easydict import EasyDict\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from src.models.protoconv.lit_module import ProtoConvLitModule\n",
    "from src.models.protoconv.train import get_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = '51f3d18dcf9a4b99b3a7b73f6989382b' \n",
    "weights_path = 'fold_0_epoch=16-val_loss_0=0.4415-val_acc_0=0.8268.ckpt'\n",
    "fold = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = ConfigParser()\n",
    "config.read('config.ini')\n",
    "\n",
    "comet_config = EasyDict(config['cometml'])\n",
    "comet_api = comet_ml.api.API(api_key=comet_config.apikey)\n",
    "experiment = comet_api.get(project_name=comet_config.projectname, workspace=comet_config.workspace,\n",
    "                           experiment=experiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/plutasnyy/anaconda3/envs/protoconv/lib/python3.8/site-packages/torchtext/data/field.py:150: UserWarning: Field class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/home/plutasnyy/anaconda3/envs/protoconv/lib/python3.8/site-packages/torchtext/data/iterator.py:48: UserWarning: BucketIterator class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.\n",
      "  warnings.warn('{} class will be retired soon and moved to torchtext.legacy. Please see the most recent release notes for further information.'.format(self.__class__.__name__), UserWarning)\n",
      "/home/plutasnyy/git/protoconv/src/models/protoconv/lit_module.py:16: UserWarning: nn.init.xavier_uniform is now deprecated in favor of nn.init.xavier_uniform_.\n",
      "  torch.nn.init.xavier_uniform(self.prototypes.data)\n"
     ]
    }
   ],
   "source": [
    "dataset = experiment.get_parameters_summary('data_set')['valueCurrent']\n",
    "kfold_split_id = list(\n",
    "    filter(lambda x: x['fileName'] == 'kfold_split_indices.csv', experiment.get_asset_list())\n",
    ")[0]['assetId']\n",
    "kfold_split_binary = experiment.get_asset(kfold_split_id, return_type=\"binary\")\n",
    "kfold_split = pd.read_csv(BytesIO(kfold_split_binary)).iloc[fold]\n",
    "\n",
    "train_index = literal_eval(kfold_split['train_indices'])\n",
    "val_index = literal_eval(kfold_split['val_indices'])\n",
    "\n",
    "df_dataset = pd.read_csv(f'data/{dataset}/data.csv')\n",
    "train_df, valid_df = df_dataset.iloc[train_index], df_dataset.iloc[val_index]\n",
    "\n",
    "TEXT, LABEL, train_loader, val_loader = get_dataset(train_df, valid_df, batch_size=1, cache=None)\n",
    "model = ProtoConvLitModule.load_from_checkpoint('checkpoints/'+weights_path, vocab_size=len(TEXT.vocab),\n",
    "                                                embedding_dim=TEXT.vocab.vectors.shape[1], lr=1, fold_id=fold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "model.eval()\n",
    "model.cuda()\n",
    "\n",
    "best_prototype_0 = None\n",
    "best_distance = float('inf')\n",
    "\n",
    "with torch.no_grad():\n",
    "    for X, batch_id in train_loader:\n",
    "        temp = model.embedding(X).permute((0, 2, 1))\n",
    "        temp = model.conv1(temp)\n",
    "        temp = model.prototype(temp) \n",
    "        prototypes_distances = temp.squeeze(0) # [Prototype, len(X)-4]\n",
    "\n",
    "        temp = -F.max_pool1d(-temp, temp.size(2))\n",
    "        best_distances = temp.view(temp.size(0), -1).squeeze(0) # [Prototype]\n",
    "        \n",
    "        if best_distances.cpu().numpy()[5] < best_distance:\n",
    "            best_distance = best_distances.cpu().numpy()[5]\n",
    "            best_prototype_0 = prototypes_distances.cpu().numpy()[5], X.cpu().numpy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "words = [TEXT.vocab.itos[j] for j in list(best_prototype_0[1].ravel())]\n",
    "weights = [0,0] + list(best_prototype_0[0].ravel()) + [0, 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['<START>', 'poor', 'agatha,', 'poor', 'reader....:', \"i've\", 'read', 'every', 'book', 'in', 'the', 'series', 'as', 'well', 'as', 'the', 'h.', 'macbeth', 'series.i', \"haven't\", 'finished', 'this', 'title', 'yet', 'but', 'agree', 'with', 'other', 'reviewers', 'regarding', 'the', 'lack', 'of', 'proofreading.', 'i', 'was', 'even', 'stymied', 'as', 'to', 'why', 'this', 'book', 'would', 'be', 'listed', 'under', '\"women-detectives-england-norfolk', 'and', 'not', 'glous.', 'or', 'warwickshire.\"a.r.', 'and', 'the', 'love', 'from', 'hell', 'is', 'a', 'bit', 'darker', 'than', 'the', 'others', 'in', 'the', 'a.r.', 'series', 'and', 'so', 'far', '(up', 'to', 'p.', '172)', 'there', 'is', 'no', 'humor', 'at', 'all.', '<END>']\n"
     ]
    }
   ],
   "source": [
    "print(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 4.052055, 6.3237424, 7.799147, 9.631209, 10.185423, 12.775558, 14.446464, 17.705328, 18.057262, 19.036509, 19.217224, 17.733301, 15.123251, 13.684399, 13.591164, 13.136839, 13.027698, 13.425535, 11.515947, 13.288067, 13.144882, 13.19454, 13.414672, 14.644038, 11.726691, 15.134076, 15.421644, 15.696607, 13.410811, 15.256836, 11.329752, 11.387961, 11.367109, 12.03377, 11.766523, 11.745758, 15.492865, 16.92241, 16.75719, 17.890406, 18.69532, 17.317614, 16.990002, 17.912249, 16.078377, 18.082115, 17.087307, 14.021075, 13.244951, 13.173656, 16.043446, 15.143722, 15.354596, 15.773807, 15.002738, 13.982317, 13.299905, 13.254038, 14.868161, 16.319359, 17.26325, 19.297539, 19.809128, 18.067993, 17.617771, 16.886292, 16.407635, 17.309208, 18.796083, 17.15499, 16.392714, 16.959522, 14.851638, 11.850729, 9.816828, 9.59249, 9.489878, 13.347328, 16.010143, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(83, 83)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(words), len(weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "import html\n",
    "from IPython.core.display import display, HTML\n",
    "\n",
    "def html_escape(text):\n",
    "    return html.escape(text)\n",
    "\n",
    "max_alpha = max(weights)\n",
    "\n",
    "highlighted_text = []\n",
    "for word, weight in zip(words, weights):\n",
    "    highlighted_text.append('<span style=\"background-color:rgba(135,206,250,' + str(weight / max_alpha) + ');\">' + html_escape(word) + '</span>')\n",
    "\n",
    "        \n",
    "highlighted_text = ' '.join(highlighted_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<span style=\"background-color:rgba(135,206,250,0.0);\">&lt;START&gt;</span> <span style=\"background-color:rgba(135,206,250,0.0);\">poor</span> <span style=\"background-color:rgba(135,206,250,0.20455493);\">agatha,</span> <span style=\"background-color:rgba(135,206,250,0.31923378);\">poor</span> <span style=\"background-color:rgba(135,206,250,0.39371482);\">reader....:</span> <span style=\"background-color:rgba(135,206,250,0.48620057);\">i&#x27;ve</span> <span style=\"background-color:rgba(135,206,250,0.5141783);\">read</span> <span style=\"background-color:rgba(135,206,250,0.6449329);\">every</span> <span style=\"background-color:rgba(135,206,250,0.72928315);\">book</span> <span style=\"background-color:rgba(135,206,250,0.89379644);\">in</span> <span style=\"background-color:rgba(135,206,250,0.91156274);\">the</span> <span style=\"background-color:rgba(135,206,250,0.9609968);\">series</span> <span style=\"background-color:rgba(135,206,250,0.97011966);\">as</span> <span style=\"background-color:rgba(135,206,250,0.8952086);\">well</span> <span style=\"background-color:rgba(135,206,250,0.7634486);\">as</span> <span style=\"background-color:rgba(135,206,250,0.69081277);\">the</span> <span style=\"background-color:rgba(135,206,250,0.6861061);\">h.</span> <span style=\"background-color:rgba(135,206,250,0.663171);\">macbeth</span> <span style=\"background-color:rgba(135,206,250,0.6576613);\">series.i</span> <span style=\"background-color:rgba(135,206,250,0.67774487);\">haven&#x27;t</span> <span style=\"background-color:rgba(135,206,250,0.5813455);\">finished</span> <span style=\"background-color:rgba(135,206,250,0.6708053);\">this</span> <span style=\"background-color:rgba(135,206,250,0.663577);\">title</span> <span style=\"background-color:rgba(135,206,250,0.6660839);\">yet</span> <span style=\"background-color:rgba(135,206,250,0.6771965);\">but</span> <span style=\"background-color:rgba(135,206,250,0.7392571);\">agree</span> <span style=\"background-color:rgba(135,206,250,0.5919842);\">with</span> <span style=\"background-color:rgba(135,206,250,0.76399505);\">other</span> <span style=\"background-color:rgba(135,206,250,0.778512);\">reviewers</span> <span style=\"background-color:rgba(135,206,250,0.7923926);\">regarding</span> <span style=\"background-color:rgba(135,206,250,0.6770016);\">the</span> <span style=\"background-color:rgba(135,206,250,0.7701922);\">lack</span> <span style=\"background-color:rgba(135,206,250,0.571946);\">of</span> <span style=\"background-color:rgba(135,206,250,0.57488453);\">proofreading.</span> <span style=\"background-color:rgba(135,206,250,0.5738319);\">i</span> <span style=\"background-color:rgba(135,206,250,0.60748607);\">was</span> <span style=\"background-color:rgba(135,206,250,0.59399503);\">even</span> <span style=\"background-color:rgba(135,206,250,0.59294677);\">stymied</span> <span style=\"background-color:rgba(135,206,250,0.78210735);\">as</span> <span style=\"background-color:rgba(135,206,250,0.8542733);\">to</span> <span style=\"background-color:rgba(135,206,250,0.8459328);\">why</span> <span style=\"background-color:rgba(135,206,250,0.9031395);\">this</span> <span style=\"background-color:rgba(135,206,250,0.94377303);\">book</span> <span style=\"background-color:rgba(135,206,250,0.87422395);\">would</span> <span style=\"background-color:rgba(135,206,250,0.8576855);\">be</span> <span style=\"background-color:rgba(135,206,250,0.90424216);\">listed</span> <span style=\"background-color:rgba(135,206,250,0.81166506);\">under</span> <span style=\"background-color:rgba(135,206,250,0.91281736);\">&quot;women-detectives-england-norfolk</span> <span style=\"background-color:rgba(135,206,250,0.86259764);\">and</span> <span style=\"background-color:rgba(135,206,250,0.7078088);\">not</span> <span style=\"background-color:rgba(135,206,250,0.6686287);\">glous.</span> <span style=\"background-color:rgba(135,206,250,0.6650296);\">or</span> <span style=\"background-color:rgba(135,206,250,0.80990165);\">warwickshire.&quot;a.r.</span> <span style=\"background-color:rgba(135,206,250,0.764482);\">and</span> <span style=\"background-color:rgba(135,206,250,0.7751273);\">the</span> <span style=\"background-color:rgba(135,206,250,0.7962898);\">love</span> <span style=\"background-color:rgba(135,206,250,0.75736487);\">from</span> <span style=\"background-color:rgba(135,206,250,0.7058522);\">hell</span> <span style=\"background-color:rgba(135,206,250,0.6714029);\">is</span> <span style=\"background-color:rgba(135,206,250,0.6690874);\">a</span> <span style=\"background-color:rgba(135,206,250,0.7505712);\">bit</span> <span style=\"background-color:rgba(135,206,250,0.82383025);\">darker</span> <span style=\"background-color:rgba(135,206,250,0.8714796);\">than</span> <span style=\"background-color:rgba(135,206,250,0.9741741);\">the</span> <span style=\"background-color:rgba(135,206,250,1.0);\">others</span> <span style=\"background-color:rgba(135,206,250,0.9121044);\">in</span> <span style=\"background-color:rgba(135,206,250,0.8893764);\">the</span> <span style=\"background-color:rgba(135,206,250,0.85245);\">a.r.</span> <span style=\"background-color:rgba(135,206,250,0.8282866);\">series</span> <span style=\"background-color:rgba(135,206,250,0.8737996);\">and</span> <span style=\"background-color:rgba(135,206,250,0.9488597);\">so</span> <span style=\"background-color:rgba(135,206,250,0.86601436);\">far</span> <span style=\"background-color:rgba(135,206,250,0.8275333);\">(up</span> <span style=\"background-color:rgba(135,206,250,0.8561469);\">to</span> <span style=\"background-color:rgba(135,206,250,0.7497371);\">p.</span> <span style=\"background-color:rgba(135,206,250,0.59824586);\">172)</span> <span style=\"background-color:rgba(135,206,250,0.49557093);\">there</span> <span style=\"background-color:rgba(135,206,250,0.48424596);\">is</span> <span style=\"background-color:rgba(135,206,250,0.4790659);\">no</span> <span style=\"background-color:rgba(135,206,250,0.6737969);\">humor</span> <span style=\"background-color:rgba(135,206,250,0.8082205);\">at</span> <span style=\"background-color:rgba(135,206,250,0.0);\">all.</span> <span style=\"background-color:rgba(135,206,250,0.0);\">&lt;END&gt;</span>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(HTML(highlighted_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "protoconv",
   "language": "python",
   "name": "protoconv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
