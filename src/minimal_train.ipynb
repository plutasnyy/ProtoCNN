{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "This notebook provides instructions for training ProtoCNN on your own data.\n",
    "Let's assume that our data is in `data/amazon/data.csv`. Let's visualize them:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Global seed set to 0\n"
     ]
    },
    {
     "data": {
      "text/plain": "0"
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "import warnings\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pytorch_lightning import seed_everything, Trainer\n",
    "from pytorch_lightning.callbacks import EarlyStopping, LearningRateMonitor, ModelCheckpoint\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torchtext import data\n",
    "from torchtext.data import BucketIterator\n",
    "from torchtext.vocab import GloVe\n",
    "\n",
    "from dataframe_dataset import DataFrameDataset\n",
    "from models.protoconv.data_visualizer import DataVisualizer\n",
    "from models.protoconv.lit_module import ProtoConvLitModule\n",
    "from utils import plot_html\n",
    "\n",
    "warnings.simplefilter(\"ignore\")\n",
    "seed_everything(0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text,label\r\n",
      "\"MUCH ADO ABOUT NOTHING: There's really nothing to watch there. There's nothing to like. Don't get me wrong - I hate violence in all its manifestations in life although I like it on screen, but here we can't even empathize this woman 'cos the movie is just sooo bad. The acting is terrible, characters do very strange and unexplainable things. You can't feel with a character when you see everything in the film is false and naive. Don't believe the taglines - there's nothing shocking in there. It's just one big waste of time. You'll feel cheated and robbed. If you hate violence in cinema, I guess you are not reading this right now and if you like shocking movies, don't bother with this one, there are plenty of others that are much more shocking and I assume you already know them all by names. Go and watch \"\"Irreversible\"\" for god's sake.\",0\r\n",
      "\"A Well Written and Enjoyable Travelogue: This book tells a very enjoyable story about Nashville's birth and culture as Music City. This is a unique travelogue that gives the visitor a real feel for Nashville and its interesting character and characters. The book is a fun read as we learn more about Music City, the music business and the author, Stephen Foehr. By the way, I've met Mr. Foehr, and the title's double enterdre is not by accident. I bought this book used on Amazon for $4.00 (including shiping); it was a steal.\",1\r\n",
      "Really Works: This I didn't noticed how well it was working until I ran out then I could really feel the diferance,1\r\n",
      "\"too predictable: this book couldn't hold my attention. i didn't really finish it, because i just didn't care enough. everything was too predictable, one thing after another. it's all been done. if you want to read fantasy that will hold your attention, read garth nix or philip pullman\",0\r\n",
      "\"Not my style: The book covers several generations, so with each generation you have to re-learn all the characters. It is difficult to keep track of who's who when every time you get to know the cast, 200 years suddenly pass and we're in the middle of a new crisis. I didn't read the whole series because of this -- it was obnoxious.\",0\r\n",
      "Very nice: I love this slip. I bought this slip to wear under my dresses that came to my knees and this works very nicely.,1\r\n",
      "NCIS Third Season: I really like the format that enables a person to play all the episodes without having to go back to the menu all the time to choose the next episode.,1\r\n",
      "\"Epic. If You Mean Epically Bad.: I hated Cadillac Records but I stayed with it for the soundtrack and the hope that it would get better. Len Chess isn't the only paternalistic thing about this film. A mishmash timeline of race cliches and lazy storytelling, Cadillac Records can't even be bothered to get it's facts straight. Saving it from one star are the performances of Columbus Short, Mos Def and Eamonn Walker, all of whom are far better than the material deserves. The film provides about as much context as a 1950's Looney Tunes featuring celebrities of the day. Even if one allows for the need to condense a large story into a short time frame, have some continuity of character inside the abbreviated version. Disjointed, relying on race role tropes instead of characterization, Cadillac Records is a lazy film that does a disservice to all whom it portrays.\",0\r\n",
      "\"One of the best movies ever!: Funny, brilliantly directed, witty script, dead-on depiction of the Italian-American family. I've seen it dozens of times and it makes me laugh out loud, always.A la famiglia!\",1\r\n"
     ]
    }
   ],
   "source": [
    "!head ../data/amazon/data.csv"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will start by loading the data:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "                                                text  label\n0  MUCH ADO ABOUT NOTHING: There's really nothing...      0\n1  A Well Written and Enjoyable Travelogue: This ...      1\n2  Really Works: This I didn't noticed how well i...      1\n3  too predictable: this book couldn't hold my at...      0\n4  Not my style: The book covers several generati...      0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>MUCH ADO ABOUT NOTHING: There's really nothing...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>A Well Written and Enjoyable Travelogue: This ...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Really Works: This I didn't noticed how well i...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>too predictable: this book couldn't hold my at...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Not my style: The book covers several generati...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_dataset = pd.read_csv(f'../data/amazon/data.csv')\n",
    "df_dataset.head()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will divide the collection into training and testing"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "outputs": [
    {
     "data": {
      "text/plain": "((24000, 2), (6000, 2))"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df, valid_df = train_test_split(df_dataset, test_size=0.2, stratify=df_dataset['label'])\n",
    "train_df.shape, valid_df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Now we will create a `torchtext` dataset, you can use any input format.\n",
    "We will use a dataset created from a table in pandas."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "outputs": [],
   "source": [
    "TEXT = data.Field(init_token='<START>', eos_token='<END>', tokenize='spacy', tokenizer_language='en',\n",
    "                  batch_first=True, lower=True, stop_words=set(string.punctuation))\n",
    "LABEL = data.Field(dtype=torch.float, is_target=True, unk_token=None, sequential=False, use_vocab=False)\n",
    "\n",
    "train_dataset = DataFrameDataset(train_df, {\n",
    "    'text': TEXT,\n",
    "    'label': LABEL\n",
    "})\n",
    "\n",
    "val_dataset = DataFrameDataset(valid_df, {\n",
    "    'text': TEXT,\n",
    "    'label': LABEL\n",
    "})\n",
    "\n",
    "train_loader, val_loader = BucketIterator.splits(\n",
    "    (train_dataset, val_dataset),\n",
    "    batch_size=32,\n",
    "    sort_key=lambda x: len(x.text),\n",
    "    device='cuda'\n",
    ")\n",
    "\n",
    "TEXT.build_vocab(train_dataset.text, vectors=GloVe('42B', cache='../.vector_cache/'))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will add saving the best model, stopping training early if there is no improvement in loss,\n",
    "and decreasing the learning rate. We will load the model with the parameters used in the publication."
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "model_checkpoint = ModelCheckpoint(filepath='../checkpoints/{epoch_0:02d}-{val_loss_0:.4f}-{val_acc_0:.4f}',\n",
    "                                   save_weights_only=True, save_top_k=1, monitor='val_acc_0', period=1)\n",
    "\n",
    "callbacks = [\n",
    "    LearningRateMonitor(logging_interval='epoch'),\n",
    "    EarlyStopping(monitor=f'val_loss_0', patience=10, verbose=True, mode='min', min_delta=0.005),\n",
    "    model_checkpoint\n",
    "]\n",
    "\n",
    "model = ProtoConvLitModule(vocab_size=len(TEXT.vocab), embedding_dim=TEXT.vocab.vectors.shape[1], fold_id=0, lr=1e-3,\n",
    "                           itos=TEXT.vocab.itos, verbose_proto=False)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Start training"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: None, using: 0 TPU cores\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "Set SLURM handle signals.\n",
      "\n",
      "  | Name       | Type               | Params\n",
      "--------------------------------------------------\n",
      "0 | embedding  | Embedding          | 17.1 M\n",
      "1 | conv1      | ConvolutionalBlock | 96.2 K\n",
      "2 | prototypes | PrototypeLayer     | 12.8 K\n",
      "3 | fc1        | Linear             | 100   \n",
      "4 | train_acc  | Accuracy           | 0     \n",
      "5 | valid_acc  | Accuracy           | 0     \n",
      "6 | loss       | BCEWithLogitsLoss  | 0     \n",
      "--------------------------------------------------\n",
      "102 K     Trainable params\n",
      "17.1 M    Non-trainable params\n",
      "17.2 M    Total params\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Training', layout=Layout(flex='2'), max…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b2c6e59240b64361b02b0f06e550f5c1"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b4203bbdf9f34a748e6a9d5059b120ba"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d33d8af4c9194e2b8f9196479943e1f6"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "6e26444a8a59434a877d8d522aa0af8b"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "819bfcd042c949cf8aa25228197dc3f7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "3cd0700534e14ea8985c1a624beafb8c"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "b620a94dd80648d7ba26efde28c1de31"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5f48e945d67d4b308bd2366af8b3ea44"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d084a5c8ee4c42c7a87f06d35418e506"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "357c8151ad144b47bff7c1ea2ee433e8"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e4bd98f1ed8c45dca5d4d19896b90a44"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "49d0574f9a4e4680975b78bfc3536297"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "0251b72f799241cb98ee08388117516a"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "dd16077e497c45c0a83cab90027e0463"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5ccc9542e7e64516868b70633a3cd5dd"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    14: reducing learning rate of group 0 to 1.0000e-04.\n"
     ]
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "444c3143a1264d7781ab2dfdaa21809d"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "f665ede08c12475295b154a9b84301f7"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "5b60ccd52a3e45c283a1bae58dc845f2"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "d43b72793be3456f894b20c38d0308c4"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": "HBox(children=(FloatProgress(value=1.0, bar_style='info', description='Validating', layout=Layout(flex='2'), m…",
      "application/vnd.jupyter.widget-view+json": {
       "version_major": 2,
       "version_minor": 0,
       "model_id": "e8a91afcd1404630b6ba8d0069110106"
      }
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch    19: reducing learning rate of group 0 to 1.0000e-05.\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": "1"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer = Trainer(max_epochs=30, callbacks=callbacks, gpus=1, deterministic=True, num_sanity_val_steps=0)\n",
    "trainer.fit(model, train_dataloader=train_loader, val_dataloaders=val_loader)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "The result of the best model is stored in the model checkpointer"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "('Best accuracy: ', 0.8163333535194397)"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'Best accuracy: ', model_checkpoint.best_model_score.tolist()\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "We will now load the weights of the best model and visualize the prototypes along with the random prediction explanations"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "best_model = ProtoConvLitModule.load_from_checkpoint(model_checkpoint.best_model_path)\n",
    "data_visualizer = DataVisualizer(best_model)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<b>Prototype 1</b> (weight 1.938): good product i<br><b>Prototype 2</b> (weight 0.090): have a lot more power<br><b>Prototype 3</b> (weight 0.071): novel the author gives us<br><b>Prototype 4</b> (weight -0.005): them but they still could<br><b>Prototype 5</b> (weight -0.115): have purchased two other remanufactured<br><b>Prototype 6</b> (weight -0.157): trilogy the only minor flaw<br><b>Prototype 7</b> (weight -0.203): worked the opposite where it<br><b>Prototype 8</b> (weight -1.412): the worst"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_html(data_visualizer.visualize_prototypes())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "<IPython.core.display.HTML object>",
      "text/html": "<b>Input example</b>: <START> great deal you can not beat the deal you get on these diapers on amazon.com we have had a few problems with overnight leaks but that was after 7 8 hours of sleep and a large cup of milk or two each time <END> <br><br><b>Prediction</b>: Positive, <b>Gold standard</b>: Positive<br><br>Evidence for Negative sentiment:<br><table style=\"width:800px\"><tr><td><b>Most similar phrase</b></td><td><b>Prototype</b></td><td><b>Similarity * Weight</b></td></tr><tr><td><span\">can not beat the deal </span> </td> <td> the worst </td> <td>2.46 * 1.41 = <b>3.47</b></td></tr><tr><td><span\">beat the deal you get </span> </td> <td> worked the opposite where it </td> <td>1.00 * 0.20 = <b>0.20</b></td></tr><tr><td><span\">a large cup of milk </span> </td> <td> have purchased two other remanufactured </td> <td>0.85 * 0.12 = <b>0.10</b></td></tr></table>Sum of evidence: <b>3.85</b><br><br>Evidence for Positive sentiment:<br><table style=\"width:800px\"><tr><td><b>Most similar phrase</b></td><td><b>Prototype</b></td><td><b>Similarity * Weight</b></td></tr><tr><td><span\">great deal you can not </span> </td> <td> good product i </td> <td>3.72 * 1.94 = <b>7.21</b></td></tr><tr><td><span\">great deal you can not </span> </td> <td> have a lot more power </td> <td>1.00 * 0.09 = <b>0.09</b></td></tr><tr><td><span\">the deal you get on </span> </td> <td> novel the author gives us </td> <td>1.20 * 0.07 = <b>0.08</b></td></tr></table>Sum of evidence: <b>7.38</b><br><br>=============================================<br><b>Input example</b>: <START> reviewer big zach not a kids review although a kid do nt bother with this crap it is one of the worst if not the worst movies that i have ever seen it has bad acting story and it is so so boring i do nt understand the point of this movie terrible dont bother <END> <br><br><b>Prediction</b>: Negative, <b>Gold standard</b>: Negative<br><br>Evidence for Negative sentiment:<br><table style=\"width:800px\"><tr><td><b>Most similar phrase</b></td><td><b>Prototype</b></td><td><b>Similarity * Weight</b></td></tr><tr><td><span\">is one of the worst </span> </td> <td> the worst </td> <td>6.70 * 1.41 = <b>9.46</b></td></tr><tr><td><span\">it is one of the </span> </td> <td> worked the opposite where it </td> <td>1.11 * 0.20 = <b>0.23</b></td></tr><tr><td><span\">it is one of the </span> </td> <td> have purchased two other remanufactured </td> <td>1.17 * 0.12 = <b>0.13</b></td></tr></table>Sum of evidence: <b>9.93</b><br><br>Evidence for Positive sentiment:<br><table style=\"width:800px\"><tr><td><b>Most similar phrase</b></td><td><b>Prototype</b></td><td><b>Similarity * Weight</b></td></tr><tr><td><span\">reviewer big zach not a </span> </td> <td> good product i </td> <td>1.34 * 1.94 = <b>2.59</b></td></tr><tr><td><span\">reviewer big zach not a </span> </td> <td> have a lot more power </td> <td>1.38 * 0.09 = <b>0.12</b></td></tr><tr><td><span\">reviewer big zach not a </span> </td> <td> novel the author gives us </td> <td>1.08 * 0.07 = <b>0.08</b></td></tr></table>Sum of evidence: <b>2.79</b><br><br>=============================================<br><b>Input example</b>: <START> could this movie get any dumber i saw this movie after hearing that it was one of the scariest movies ever .... i think not the actors were awful and the plot was too unbelievable i was laughing almost the whole time this is n't a scary movie i would not reccomend this movie to anyone .... it 's not worth buying <END> <br><br><b>Prediction</b>: Negative, <b>Gold standard</b>: Negative<br><br>Evidence for Negative sentiment:<br><table style=\"width:800px\"><tr><td><b>Most similar phrase</b></td><td><b>Prototype</b></td><td><b>Similarity * Weight</b></td></tr><tr><td><span\">would not reccomend this movie </span> </td> <td> the worst </td> <td>5.83 * 1.41 = <b>8.23</b></td></tr><tr><td><span\">movie after hearing that it </span> </td> <td> worked the opposite where it </td> <td>1.01 * 0.20 = <b>0.20</b></td></tr><tr><td><span\">and the plot was too </span> </td> <td> have purchased two other remanufactured </td> <td>1.20 * 0.12 = <b>0.14</b></td></tr></table>Sum of evidence: <b>8.70</b><br><br>Evidence for Positive sentiment:<br><table style=\"width:800px\"><tr><td><b>Most similar phrase</b></td><td><b>Prototype</b></td><td><b>Similarity * Weight</b></td></tr><tr><td><span\">it &#x27;s not worth buying </span> </td> <td> good product i </td> <td>1.94 * 1.94 = <b>3.76</b></td></tr><tr><td><span\">was laughing almost the whole </span> </td> <td> have a lot more power </td> <td>0.79 * 0.09 = <b>0.07</b></td></tr><tr><td><span\">laughing almost the whole time </span> </td> <td> novel the author gives us </td> <td>0.97 * 0.07 = <b>0.07</b></td></tr></table>Sum of evidence: <b>3.90</b><br><br>=============================================<br><b>Input example</b>: <START> not her best ... to be perfectly honest i did n't like amarantine very much only a little whereas i love her other albums this is definitely not her best and five years is too long to wait for a rather disappointing album the songs are reminiscent i do no want to use the word rehashed of her older -and <unk> ones one example is someone said goodbye which is very similar in theme and rythm to one by one in a day without rain buy it only if you 're a die hard enya fan but if you 're new to her music try her master pieces watermark the memory of trees and the <unk> <END> <br><br><b>Prediction</b>: Negative, <b>Gold standard</b>: Negative<br><br>Evidence for Negative sentiment:<br><table style=\"width:800px\"><tr><td><b>Most similar phrase</b></td><td><b>Prototype</b></td><td><b>Similarity * Weight</b></td></tr><tr><td><span\">not her best ... to </span> </td> <td> the worst </td> <td>5.06 * 1.41 = <b>7.15</b></td></tr><tr><td><span\">is very similar in theme </span> </td> <td> worked the opposite where it </td> <td>0.97 * 0.20 = <b>0.20</b></td></tr><tr><td><span\">theme and rythm to one </span> </td> <td> have purchased two other remanufactured </td> <td>1.04 * 0.12 = <b>0.12</b></td></tr></table>Sum of evidence: <b>7.59</b><br><br>Evidence for Positive sentiment:<br><table style=\"width:800px\"><tr><td><b>Most similar phrase</b></td><td><b>Prototype</b></td><td><b>Similarity * Weight</b></td></tr><tr><td><span\">is very similar in theme </span> </td> <td> good product i </td> <td>3.13 * 1.94 = <b>6.07</b></td></tr><tr><td><span\">years is too long to </span> </td> <td> have a lot more power </td> <td>1.26 * 0.09 = <b>0.11</b></td></tr><tr><td><span\">you &#x27;re new to her </span> </td> <td> novel the author gives us </td> <td>1.13 * 0.07 = <b>0.08</b></td></tr></table>Sum of evidence: <b>6.26</b><br><br>=============================================<br><b>Input example</b>: <START> criminally under rated album i have to admit i 'm a recent fan of the black crowes and by your side was their first complete album that i listened to but not the last because of this i album i got everything that they have ever released and i have to say this one is definately their best from by your side to go tell the congregation to virtue and vice there is not a minute of music on this album that does not rock i read a biography of the band at the apple music store and that writer said it best this album is criminally under rated if you 're a black crowes fan then you 'll love this album <END> <br><br><b>Prediction</b>: Positive, <b>Gold standard</b>: Positive<br><br>Evidence for Negative sentiment:<br><table style=\"width:800px\"><tr><td><b>Most similar phrase</b></td><td><b>Prototype</b></td><td><b>Similarity * Weight</b></td></tr><tr><td><span\">but not the last because </span> </td> <td> the worst </td> <td>4.04 * 1.41 = <b>5.70</b></td></tr><tr><td><span\">at the apple music store </span> </td> <td> worked the opposite where it </td> <td>1.01 * 0.20 = <b>0.21</b></td></tr><tr><td><span\">a recent fan of the </span> </td> <td> have purchased two other remanufactured </td> <td>1.35 * 0.12 = <b>0.16</b></td></tr></table>Sum of evidence: <b>6.18</b><br><br>Evidence for Positive sentiment:<br><table style=\"width:800px\"><tr><td><b>Most similar phrase</b></td><td><b>Prototype</b></td><td><b>Similarity * Weight</b></td></tr><tr><td><span\">you &#x27;ll love this album </span> </td> <td> good product i </td> <td>3.61 * 1.94 = <b>7.00</b></td></tr><tr><td><span\">you &#x27;ll love this album </span> </td> <td> have a lot more power </td> <td>0.91 * 0.09 = <b>0.08</b></td></tr><tr><td><span\">a minute of music on </span> </td> <td> novel the author gives us </td> <td>0.97 * 0.07 = <b>0.07</b></td></tr></table>Sum of evidence: <b>7.15</b><br><br>============================================="
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_html(data_visualizer.visualize_random_predictions(val_loader, n=5))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}